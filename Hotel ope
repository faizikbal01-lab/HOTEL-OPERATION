{"cells":[{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv('/content/hotel booking.csv')\n","\n","df['arrival_date'] = pd.to_datetime(df['arrival_date_year'].astype(str) + '-' + df['arrival_date_month'] + '-' + df['arrival_date_day_of_month'].astype(str))\n","df['reservation_status_date'] = pd.to_datetime(df['reservation_status_date'])\n","\n","df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"ykIhLdE_uCo0","executionInfo":{"status":"error","timestamp":1771099983257,"user_tz":480,"elapsed":243,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}},"outputId":"f7eb662c-d4c1-4dcb-8836-854c739d7138"},"execution_count":1,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/hotel booking.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3938335347.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/hotel booking.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arrival_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arrival_date_year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arrival_date_month'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arrival_date_day_of_month'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/hotel booking.csv'"]}]},{"cell_type":"code","source":["distribution = df.groupby(['hotel', 'arrival_date_month', 'market_segment']).size().unstack(fill_value=0)\n","print(distribution)"],"metadata":{"id":"Y6ptHTWcuydH","executionInfo":{"status":"aborted","timestamp":1771099983402,"user_tz":480,"elapsed":204,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","cancellation_by_lead_time = df.groupby('lead_time')['is_canceled'].mean().reset_index()\n","\n","plt.figure(figsize=(12, 6))\n","sns.scatterplot(x='lead_time', y='is_canceled', data=cancellation_by_lead_time, alpha=0.6)\n","plt.title('Cancellation Rate vs. Lead Time (Scatter Plot)')\n","plt.xlabel('Lead Time (days)')\n","plt.ylabel('Cancellation Rate')\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"KFb-SfZ0vGcZ","executionInfo":{"status":"aborted","timestamp":1771099983410,"user_tz":480,"elapsed":207,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","adr_over_time = df.groupby('arrival_date')['adr'].mean().reset_index()\n","\n","plt.figure(figsize=(15, 7))\n","sns.lineplot(x='arrival_date', y='adr', data=adr_over_time)\n","plt.title('Average Daily Rate (ADR) Over Time')\n","plt.xlabel('Arrival Date')\n","plt.ylabel('Average Daily Rate (EUR)')\n","plt.grid(True)\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"RnlYfHZVvWBb","executionInfo":{"status":"aborted","timestamp":1771099983414,"user_tz":480,"elapsed":207,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Frequency of special requests:\")\n","print(df['total_of_special_requests'].value_counts().sort_index())\n","\n","cancellation_by_special_requests = df.groupby('total_of_special_requests')['is_canceled'].mean().reset_index()\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x='total_of_special_requests', y='is_canceled', data=cancellation_by_special_requests)\n","plt.title('Cancellation Rate vs. Number of Special Requests')\n","plt.xlabel('Number of Special Requests')\n","plt.ylabel('Cancellation Rate')\n","plt.grid(axis='y')\n","plt.show()"],"metadata":{"id":"3TTIqlPtvtm-","executionInfo":{"status":"aborted","timestamp":1771099983418,"user_tz":480,"elapsed":925,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_lead_time = df['lead_time'].mean()\n","print(f\"The average lead time is: {mean_lead_time:.2f} days\")"],"metadata":{"id":"G3pwVLmQwGYa","executionInfo":{"status":"aborted","timestamp":1771099983423,"user_tz":480,"elapsed":922,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c5f4e3e3","executionInfo":{"status":"aborted","timestamp":1771099983428,"user_tz":480,"elapsed":918,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["cancellation_by_hotel = df.groupby('hotel')['is_canceled'].mean().reset_index()\n","print(\"Cancellation Rate by Hotel Type:\")\n","print(cancellation_by_hotel)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aa2117ca","executionInfo":{"status":"aborted","timestamp":1771099983432,"user_tz":480,"elapsed":911,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure(figsize=(8, 5))\n","sns.barplot(x='hotel', y='is_canceled', hue='hotel', data=cancellation_by_hotel, palette='viridis', legend=False)\n","plt.title('Cancellation Rate by Hotel Type')\n","plt.xlabel('Hotel Type')\n","plt.ylabel('Cancellation Rate')\n","plt.ylim(0, 0.5) # Set y-axis limit for better comparison, as rates are typically below 0.5\n","plt.grid(axis='y', linestyle='--', alpha=0.7)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"af741120","executionInfo":{"status":"aborted","timestamp":1771099983435,"user_tz":480,"elapsed":897,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","bookings_by_hotel = df['hotel'].value_counts().reset_index()\n","bookings_by_hotel.columns = ['hotel', 'number_of_bookings']\n","\n","print(\"Number of bookings by hotel type:\")\n","print(bookings_by_hotel)\n","\n","plt.figure(figsize=(8, 6))\n","sns.barplot(x='hotel', y='number_of_bookings', hue='hotel', data=bookings_by_hotel, palette='Paired', legend=False)\n","plt.title('Number of Bookings by Hotel Type')\n","plt.xlabel('Hotel Type')\n","plt.ylabel('Number of Bookings')\n","plt.grid(axis='y', linestyle='--', alpha=0.7)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_canceled_bookings = df['is_canceled'].sum()\n","print(f\"Total number of canceled bookings: {total_canceled_bookings}\")"],"metadata":{"id":"jwk7ahpJwsgL","executionInfo":{"status":"aborted","timestamp":1771099983440,"user_tz":480,"elapsed":894,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["most_frequent_arrival_month = df['arrival_date_month'].mode()[0]\n","print(f\"The month with the highest number of arrivals is: {most_frequent_arrival_month}\")"],"metadata":{"id":"ulogCTiNxwJf","executionInfo":{"status":"aborted","timestamp":1771099983446,"user_tz":480,"elapsed":893,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"54d8e4ad","executionInfo":{"status":"aborted","timestamp":1771099983450,"user_tz":480,"elapsed":884,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","bookings_by_room_type = df['reserved_room_type'].value_counts().reset_index()\n","bookings_by_room_type.columns = ['reserved_room_type', 'number_of_bookings']\n","\n","print(\"Number of bookings by reserved room type:\")\n","print(bookings_by_room_type)\n","\n","most_common_room_type = df['reserved_room_type'].value_counts().idxmax()\n","print(f\"\\nThe reserved room type with the highest booking count is: {most_common_room_type}\")\n","\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x='reserved_room_type', y='number_of_bookings', hue='reserved_room_type', data=bookings_by_room_type, palette='tab10', legend=False)\n","plt.title('Number of Bookings by Reserved Room Type')\n","plt.xlabel('Reserved Room Type')\n","plt.ylabel('Number of Bookings')\n","plt.xticks(rotation=45, ha='right')\n","plt.grid(axis='y', linestyle='--', alpha=0.7)\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"23af541f","executionInfo":{"status":"aborted","timestamp":1771099983453,"user_tz":480,"elapsed":878,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["mean_stay_duration_by_guest_type = df.groupby('is_repeated_guest')['total_stays'].mean().reset_index()\n","print(\"Average Stay Duration by Guest Type:\")\n","print(mean_stay_duration_by_guest_type)\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure(figsize=(8, 5))\n","sns.barplot(x='is_repeated_guest', y='total_stays', data=mean_stay_duration_by_guest_type, palette='coolwarm', hue='is_repeated_guest', legend=False)\n","plt.title('Average Stay Duration by Guest Type')\n","plt.xlabel('Guest Type (0 = New Guest, 1 = Repeated Guest)')\n","plt.ylabel('Average Total Stays (Nights)')\n","plt.xticks([0, 1], ['New Guest', 'Repeated Guest'])\n","plt.grid(axis='y', linestyle='--', alpha=0.7)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"60385160","executionInfo":{"status":"aborted","timestamp":1771099983458,"user_tz":480,"elapsed":865,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","adr_by_special_requests = df.groupby('total_of_special_requests')['adr'].mean().reset_index()\n","\n","print(\"Average Daily Rate (ADR) by Number of Special Requests:\")\n","print(adr_by_special_requests)\n","\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x='total_of_special_requests', y='adr', hue='total_of_special_requests', data=adr_by_special_requests, palette='magma', legend=False)\n","plt.title('Average Daily Rate (ADR) vs. Number of Special Requests')\n","plt.xlabel('Number of Special Requests')\n","plt.ylabel('Average Daily Rate (EUR)')\n","plt.grid(axis='y', linestyle='--', alpha=0.7)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a7738e32","executionInfo":{"status":"aborted","timestamp":1771099983463,"user_tz":480,"elapsed":863,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["df['total_stays'] = df['stays_in_week_nights'] + df['stays_in_weekend_nights']\n","df['revenue_per_booking'] = df['adr'] * df['total_stays']\n","\n","monthly_revenue = df.groupby('arrival_date_month')['revenue_per_booking'].sum().reset_index()\n","monthly_revenue_sorted = monthly_revenue.sort_values(by='revenue_per_booking', ascending=False)\n","\n","print(\"Total Revenue by Month:\")\n","print(monthly_revenue_sorted)\n","\n","highest_revenue_month = monthly_revenue_sorted.iloc[0]\n","print(f\"\\nThe month with the highest total revenue is {highest_revenue_month['arrival_date_month']} with a total revenue of {highest_revenue_month['revenue_per_booking']:.2f} EUR.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"306e53d3","executionInfo":{"status":"aborted","timestamp":1771099983467,"user_tz":480,"elapsed":857,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Define a consistent order for months for better visualization\n","month_order = ['January', 'February', 'March', 'April', 'May', 'June',\n","               'July', 'August', 'September', 'October', 'November', 'December']\n","monthly_revenue['arrival_date_month'] = pd.Categorical(monthly_revenue['arrival_date_month'], categories=month_order, ordered=True)\n","monthly_revenue = monthly_revenue.sort_values('arrival_date_month')\n","\n","plt.figure(figsize=(12, 7))\n","sns.barplot(x='arrival_date_month', y='revenue_per_booking', hue='arrival_date_month', data=monthly_revenue, palette='viridis', legend=False)\n","plt.title('Total Revenue by Month')\n","plt.xlabel('Arrival Month')\n","plt.ylabel('Total Revenue (EUR)')\n","plt.xticks(rotation=45, ha='right')\n","plt.grid(axis='y', linestyle='--', alpha=0.7)\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c484e937","executionInfo":{"status":"aborted","timestamp":1771099983470,"user_tz":480,"elapsed":848,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","adr_per_year = df.groupby('arrival_date_year')['adr'].mean().reset_index()\n","\n","plt.figure(figsize=(10, 6))\n","sns.lineplot(x='arrival_date_year', y='adr', data=adr_per_year, marker='o')\n","plt.title('Average Daily Rate (ADR) Per Year')\n","plt.xlabel('Arrival Year')\n","plt.ylabel('Average Daily Rate (EUR)')\n","plt.grid(True)\n","plt.xticks(adr_per_year['arrival_date_year'].unique()) # Ensure all years are shown as ticks\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eb103e30","executionInfo":{"status":"aborted","timestamp":1771099983474,"user_tz":480,"elapsed":845,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["mean_prev_cancellations_by_hotel = df.groupby('hotel')['previous_cancellations'].mean().reset_index()\n","print(\"Average Previous Cancellations by Hotel Type:\")\n","print(mean_prev_cancellations_by_hotel)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b906ea6f","executionInfo":{"status":"aborted","timestamp":1771099983477,"user_tz":480,"elapsed":842,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["bookings_with_agents = df['agent'].count()\n","print(f\"Number of bookings made through travel agents: {bookings_with_agents}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0df87f22","executionInfo":{"status":"aborted","timestamp":1771099983487,"user_tz":480,"elapsed":844,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["df['total_stays'] = df['stays_in_week_nights'] + df['stays_in_weekend_nights']\n","mean_total_stays = df['total_stays'].mean()\n","print(f\"The average total stay duration is: {mean_total_stays:.2f} nights\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eb194390","executionInfo":{"status":"aborted","timestamp":1771099983493,"user_tz":480,"elapsed":842,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["mean_week_nights = df['stays_in_week_nights'].mean()\n","mean_weekend_nights = df['stays_in_weekend_nights'].mean()\n","print(f\"The average number of week nights stayed is: {mean_week_nights:.2f} nights\")\n","print(f\"The average number of weekend nights stayed is: {mean_weekend_nights:.2f} nights\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dd2f5a82","executionInfo":{"status":"aborted","timestamp":1771099983499,"user_tz":480,"elapsed":841,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["parking_required_count = df[df['required_car_parking_spaces'] > 0].shape[0]\n","total_bookings = df.shape[0]\n","percentage_parking_required = (parking_required_count / total_bookings) * 100\n","\n","print(f\"Percentage of bookings requiring car parking spaces: {percentage_parking_required:.2f}%\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5331e51d","executionInfo":{"status":"aborted","timestamp":1771099983544,"user_tz":480,"elapsed":879,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["mean_adr_by_hotel = df.groupby('hotel')['adr'].mean().reset_index()\n","print(\"Average Daily Rate (ADR) by Hotel Type:\")\n","print(mean_adr_by_hotel)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"847815e3","executionInfo":{"status":"aborted","timestamp":1771099983547,"user_tz":480,"elapsed":876,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["most_bookings_country = df['country'].value_counts().idxmax()\n","print(f\"The country with the highest count of bookings is: {most_bookings_country}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c2f4b433","executionInfo":{"status":"aborted","timestamp":1771099983553,"user_tz":480,"elapsed":874,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["mean_special_requests = df['total_of_special_requests'].mean()\n","print(f\"The average number of special requests is: {mean_special_requests:.2f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"H6u4TDmxxv6E","executionInfo":{"status":"aborted","timestamp":1771099983560,"user_tz":480,"elapsed":880,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5b088706"},"source":["# Task\n","To perform a logistic regression analysis to identify significant predictors of hotel booking cancellations, and then evaluate the model's performance."]},{"cell_type":"markdown","metadata":{"id":"2333cb06"},"source":["## Prepare Data for Logistic Regression\n","\n","### Subtask:\n","Select relevant features (e.g., lead_time, booking_changes, total_of_special_requests, hotel, market_segment, deposit_type, customer_type) and the target variable (is_canceled). Handle categorical features using one-hot encoding if necessary. Split the data into training and testing sets.\n"]},{"cell_type":"markdown","metadata":{"id":"879bd706"},"source":["**Reasoning**:\n","To prepare the data for logistic regression, I will first define the features (X) and target (y), apply one-hot encoding to the specified categorical features, and then split the data into training and testing sets.\n","\n"]},{"cell_type":"code","metadata":{"id":"c8966861","executionInfo":{"status":"aborted","timestamp":1771099983564,"user_tz":480,"elapsed":877,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["from sklearn.model_selection import train_test_split\n","import pandas as pd\n","\n","# 1. Define features (X) and target variable (y)\n","numerical_features = ['lead_time', 'booking_changes', 'total_of_special_requests']\n","categorical_features = ['hotel', 'market_segment', 'deposit_type', 'customer_type']\n","target_variable = 'is_canceled'\n","\n","X = df[numerical_features + categorical_features]\n","y = df[target_variable]\n","\n","# 2. Apply one-hot encoding to categorical features\n","X = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n","\n","# Display the first few rows of the processed features and their shape\n","print(\"Processed features (X) head:\")\n","print(X.head())\n","print(f\"\\nShape of processed features (X): {X.shape}\")\n","print(f\"Shape of target variable (y): {y.shape}\")\n","\n","# 3. Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","print(f\"\\nShape of X_train: {X_train.shape}\")\n","print(f\"Shape of X_test: {X_test.shape}\")\n","print(f\"Shape of y_train: {y_train.shape}\")\n","print(f\"Shape of y_test: {y_test.shape}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ba5f9071"},"source":["## Train Logistic Regression Model\n","\n","### Subtask:\n","Initialize and train a logistic regression model using the prepared training data. The target variable is 'is_canceled'.\n"]},{"cell_type":"markdown","metadata":{"id":"56e40c91"},"source":["**Reasoning**:\n","The user wants to initialize and train a logistic regression model. This involves importing the `LogisticRegression` class, instantiating it with specified parameters, and then fitting it to the training data (X_train and y_train).\n","\n"]},{"cell_type":"code","metadata":{"id":"d7b56408","executionInfo":{"status":"aborted","timestamp":1771099983569,"user_tz":480,"elapsed":876,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["from sklearn.linear_model import LogisticRegression\n","\n","# Initialize the Logistic Regression model\n","# Set solver='liblinear' for smaller datasets and to handle potential convergence issues\n","# Set random_state for reproducibility\n","model = LogisticRegression(solver='liblinear', random_state=42)\n","\n","# Train the model using the training data\n","model.fit(X_train, y_train)\n","\n","print(\"Logistic Regression model trained successfully.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"25b401bf"},"source":["## Evaluate Model Performance\n","\n","### Subtask:\n","Evaluate the trained logistic regression model using the test set. Calculate and display relevant metrics such as accuracy, precision, recall, and F1-score.\n"]},{"cell_type":"markdown","metadata":{"id":"8e755178"},"source":["**Reasoning**:\n","I need to evaluate the trained logistic regression model by making predictions on the test set and then calculating common classification metrics like accuracy, precision, recall, and F1-score using scikit-learn's `accuracy_score` and `classification_report`.\n","\n"]},{"cell_type":"code","metadata":{"id":"0f5077a9","executionInfo":{"status":"aborted","timestamp":1771099983572,"user_tz":480,"elapsed":872,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["from sklearn.metrics import accuracy_score, classification_report\n","\n","# 1. Use the trained model to make predictions on the X_test data\n","y_pred = model.predict(X_test)\n","\n","# 2. Calculate the accuracy of the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Model Accuracy: {accuracy:.4f}\")\n","\n","# 3. Generate a classification report\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5a4d1250"},"source":["## Identify Significant Predictors\n","\n","### Subtask:\n","Extract the coefficients and p-values (or similar statistical significance measures) for each feature from the trained logistic regression model to identify the most significant predictors of cancellation.\n"]},{"cell_type":"markdown","metadata":{"id":"831f91fe"},"source":["**Reasoning**:\n","To identify significant predictors, I will extract coefficients from the `sklearn` model and use `statsmodels` to calculate p-values, then combine and sort them to highlight the most impactful and statistically significant features.\n","\n"]},{"cell_type":"code","metadata":{"id":"baecd946","executionInfo":{"status":"aborted","timestamp":1771099983575,"user_tz":480,"elapsed":863,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["import statsmodels.api as sm\n","\n","# 1. Extract the coefficients from the trained model\n","coefficients = model.coef_[0]\n","intercept = model.intercept_[0]\n","\n","# Get feature names from X_train (which includes one-hot encoded columns)\n","feature_names = X_train.columns.tolist()\n","\n","# Create a DataFrame for coefficients including the intercept\n","coefficients_df = pd.DataFrame({\n","    'Feature': ['Intercept'] + feature_names,\n","    'Coefficient': [intercept] + coefficients.tolist()\n","})\n","\n","print(\"Coefficients from scikit-learn model:\")\n","print(coefficients_df)\n","\n","# 3. Add a constant term to X_train for statsmodels\n","X_train_sm = sm.add_constant(X_train)\n","\n","# 4. Initialize and fit a logistic regression model using statsmodels\n","sm_model = sm.Logit(y_train, X_train_sm)\n","results = sm_model.fit(disp=False) # disp=False to suppress convergence output\n","\n","# 5. Extract the p-values\n","p_values = results.pvalues\n","\n","# Create a DataFrame for p-values\n","p_values_df = pd.DataFrame({\n","    'Feature': p_values.index,\n","    'P-value': p_values.values\n","})\n","\n","# 6. Combine coefficients and p-values into a single DataFrame\n","# Merge based on 'Feature' column, ensuring consistent feature names\n","# The intercept will be handled if it's consistently named in both DataFrames\n","combined_df = coefficients_df.merge(p_values_df, on='Feature', how='left')\n","\n","# Sort by the absolute value of coefficients\n","combined_df['Abs_Coefficient'] = combined_df['Coefficient'].abs()\n","combined_df = combined_df.sort_values(by='Abs_Coefficient', ascending=False).drop(columns=['Abs_Coefficient'])\n","\n","print(\"\\nCombined Coefficients and P-values (Sorted by Absolute Coefficient):\")\n","print(combined_df)\n","\n","# 7. Identify and print significant predictors (p-value < 0.05)\n","significant_predictors = combined_df[combined_df['P-value'] < 0.05]\n","\n","print(\"\\nSignificant Predictors (P-value < 0.05):\")\n","print(significant_predictors)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a8ca4289"},"source":["**Reasoning**:\n","The error `ValueError: Pandas data cast to numpy dtype of object` indicates that `statsmodels` is encountering boolean columns in `X_train_sm` that it cannot directly convert to numerical format. To fix this, I need to explicitly convert all boolean columns in `X_train_sm` to integers (0 or 1) before fitting the `statsmodels.Logit` model.\n","\n"]},{"cell_type":"code","metadata":{"id":"4325a300","executionInfo":{"status":"aborted","timestamp":1771099983579,"user_tz":480,"elapsed":854,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["import statsmodels.api as sm\n","\n","# 1. Extract the coefficients from the trained model\n","coefficients = model.coef_[0]\n","intercept = model.intercept_[0]\n","\n","# Get feature names from X_train (which includes one-hot encoded columns)\n","feature_names = X_train.columns.tolist()\n","\n","# Create a DataFrame for coefficients including the intercept\n","coefficients_df = pd.DataFrame({\n","    'Feature': ['Intercept'] + feature_names,\n","    'Coefficient': [intercept] + coefficients.tolist()\n","})\n","\n","print(\"Coefficients from scikit-learn model:\")\n","print(coefficients_df)\n","\n","# 3. Add a constant term to X_train for statsmodels\n","X_train_sm = sm.add_constant(X_train)\n","\n","# Convert boolean columns to integers (0 or 1) for statsmodels compatibility\n","for col in X_train_sm.select_dtypes(include='bool').columns:\n","    X_train_sm[col] = X_train_sm[col].astype(int)\n","\n","# 4. Initialize and fit a logistic regression model using statsmodels\n","sm_model = sm.Logit(y_train, X_train_sm)\n","results = sm_model.fit(disp=False) # disp=False to suppress convergence output\n","\n","# 5. Extract the p-values\n","p_values = results.pvalues\n","\n","# Create a DataFrame for p-values\n","p_values_df = pd.DataFrame({\n","    'Feature': p_values.index,\n","    'P-value': p_values.values\n","})\n","\n","# 6. Combine coefficients and p-values into a single DataFrame\n","# Merge based on 'Feature' column, ensuring consistent feature names\n","# The intercept will be handled if it's consistently named in both DataFrames\n","combined_df = coefficients_df.merge(p_values_df, on='Feature', how='left')\n","\n","# Sort by the absolute value of coefficients\n","combined_df['Abs_Coefficient'] = combined_df['Coefficient'].abs()\n","combined_df = combined_df.sort_values(by='Abs_Coefficient', ascending=False).drop(columns=['Abs_Coefficient'])\n","\n","print(\"\\nCombined Coefficients and P-values (Sorted by Absolute Coefficient):\")\n","print(combined_df)\n","\n","# 7. Identify and print significant predictors (p-value < 0.05)\n","significant_predictors = combined_df[combined_df['P-value'] < 0.05]\n","\n","print(\"\\nSignificant Predictors (P-value < 0.05):\")\n","print(significant_predictors)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ce6e61f"},"source":["**Reasoning**:\n","The `LinAlgError: Singular matrix` indicates perfect multicollinearity in the design matrix `X_train_sm`. This often happens when one-hot encoded variables, after dropping the first category (using `drop_first=True`), still sum to a constant (e.g., 1) for all observations, creating perfect collinearity with the intercept term. Given the low frequency of `market_segment_Undefined` (4 entries in the original dataset), it's a strong candidate for causing this issue. Removing this column will mitigate the multicollinearity and allow `statsmodels` to fit the model.\n","\n"]},{"cell_type":"code","metadata":{"id":"e80e2dd6","executionInfo":{"status":"aborted","timestamp":1771099983582,"user_tz":480,"elapsed":851,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["import statsmodels.api as sm\n","\n","# 1. Extract the coefficients from the trained model\n","coefficients = model.coef_[0]\n","intercept = model.intercept_[0]\n","\n","# Get feature names from X_train (which includes one-hot encoded columns)\n","feature_names = X_train.columns.tolist()\n","\n","# Create a DataFrame for coefficients including the intercept\n","coefficients_df = pd.DataFrame({\n","    'Feature': ['Intercept'] + feature_names,\n","    'Coefficient': [intercept] + coefficients.tolist()\n","})\n","\n","print(\"Coefficients from scikit-learn model:\")\n","print(coefficients_df)\n","\n","# 3. Add a constant term to X_train for statsmodels\n","X_train_sm = sm.add_constant(X_train)\n","\n","# Convert boolean columns to integers (0 or 1) for statsmodels compatibility\n","for col in X_train_sm.select_dtypes(include='bool').columns:\n","    X_train_sm[col] = X_train_sm[col].astype(int)\n","\n","# --- FIX: Handle singular matrix error by dropping potentially problematic columns ---\n","# The 'market_segment_Undefined' column often causes singularity due to very few observations\n","# or perfect multicollinearity when combined with a constant and other market segment dummies.\n","if 'market_segment_Undefined' in X_train_sm.columns:\n","    X_train_sm = X_train_sm.drop(columns=['market_segment_Undefined'])\n","# If other columns also cause issues, they would need to be identified and dropped similarly.\n","\n","# 4. Initialize and fit a logistic regression model using statsmodels\n","sm_model = sm.Logit(y_train, X_train_sm)\n","results = sm_model.fit(disp=False) # disp=False to suppress convergence output\n","\n","# 5. Extract the p-values\n","p_values = results.pvalues\n","\n","# Create a DataFrame for p-values\n","p_values_df = pd.DataFrame({\n","    'Feature': p_values.index,\n","    'P-value': p_values.values\n","})\n","\n","# 6. Combine coefficients and p-values into a single DataFrame\n","# Merge based on 'Feature' column, ensuring consistent feature names\n","# The intercept will be handled if it's consistently named in both DataFrames\n","combined_df = coefficients_df.merge(p_values_df, on='Feature', how='left')\n","\n","# Sort by the absolute value of coefficients\n","combined_df['Abs_Coefficient'] = combined_df['Coefficient'].abs()\n","combined_df = combined_df.sort_values(by='Abs_Coefficient', ascending=False).drop(columns=['Abs_Coefficient'])\n","\n","print(\"\\nCombined Coefficients and P-values (Sorted by Absolute Coefficient):\")\n","print(combined_df)\n","\n","# 7. Identify and print significant predictors (p-value < 0.05)\n","significant_predictors = combined_df[combined_df['P-value'] < 0.05]\n","\n","print(\"\\nSignificant Predictors (P-value < 0.05):\")\n","print(significant_predictors)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5169524a"},"source":["# Task\n","## Prepare Data for Multiple Regression\n","\n","### Subtask:\n","Select the 'adults', 'children', and 'babies' columns as independent variables (X) and 'adr' as the dependent variable (y). Check for and handle any missing values in these columns to ensure the model runs correctly.\n","\n","### Reasoning:\n","To prepare the data for multiple regression, I will first define the independent variables (X) as 'adults', 'children', and 'babies', and the dependent variable (y) as 'adr'. I will then check for any missing values in these selected columns and, if found, address them, in this case, by dropping the few rows with missing `children` values, as this will not significantly impact the dataset. I'll then display the shape of the prepared data."]},{"cell_type":"markdown","metadata":{"id":"5dd54d4b"},"source":["## Prepare Data for Multiple Regression\n","\n","### Subtask:\n","Select the 'adults', 'children', and 'babies' columns as independent variables (X) and 'adr' as the dependent variable (y). Check for and handle any missing values in these columns to ensure the model runs correctly.\n"]},{"cell_type":"markdown","metadata":{"id":"d05b5352"},"source":["**Reasoning**:\n","To prepare the data for multiple regression, I will first create a new DataFrame with the specified columns, check for and handle missing values, then define the independent (X) and dependent (y) variables, and finally print their shapes for verification.\n","\n"]},{"cell_type":"code","metadata":{"id":"7b26a2c3","executionInfo":{"status":"aborted","timestamp":1771099983586,"user_tz":480,"elapsed":849,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["import pandas as pd\n","\n","# 1. Create a new DataFrame `regression_df` with specified columns\n","regression_df = df[['adults', 'children', 'babies', 'adr']].copy()\n","\n","# 2. Check for any missing values in `regression_df`\n","print(\"Missing values before handling:\")\n","print(regression_df.isnull().sum())\n","\n","# 3. Remove any rows with missing values from `regression_df`\n","regression_df.dropna(inplace=True)\n","\n","print(\"\\nMissing values after handling:\")\n","print(regression_df.isnull().sum())\n","\n","# 4. Define the independent variables X\n","X = regression_df[['adults', 'children', 'babies']]\n","\n","# 5. Define the dependent variable y\n","y = regression_df['adr']\n","\n","# 6. Print the shape of X and y\n","print(f\"\\nShape of independent variables (X): {X.shape}\")\n","print(f\"Shape of dependent variable (y): {y.shape}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"00e858d6"},"source":["## Build Multiple Regression Model\n","\n","### Subtask:\n","Initialize and train a multiple linear regression model using the prepared data. The goal is to model 'adr' based on the number of adults, children, and babies.\n"]},{"cell_type":"markdown","metadata":{"id":"378b8dbe"},"source":["**Reasoning**:\n","To build a multiple linear regression model, I will follow the instructions to import `statsmodels.api`, add a constant to the independent variables, and then initialize and fit the OLS model.\n","\n"]},{"cell_type":"code","metadata":{"id":"86a41e14","executionInfo":{"status":"aborted","timestamp":1771099983590,"user_tz":480,"elapsed":847,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["import statsmodels.api as sm\n","\n","# 1. Add a constant term to the independent variables X\n","X_const = sm.add_constant(X)\n","\n","# 2. Initialize and train a multiple linear regression model\n","#    using sm.OLS() with y as the dependent variable and X_const as the independent variables.\n","model = sm.OLS(y, X_const)\n","\n","# 3. Fit the model and store the results\n","model_results = model.fit()\n","\n","print(\"Multiple linear regression model trained successfully.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bc4c6486"},"source":["**Reasoning**:\n","The previous step successfully trained a multiple linear regression model. The next logical step is to evaluate its performance by displaying the model summary, which includes key statistics such as R-squared, coefficients, and p-values.\n","\n"]},{"cell_type":"code","metadata":{"id":"ae88810d","executionInfo":{"status":"aborted","timestamp":1771099983595,"user_tz":480,"elapsed":845,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["print(model_results.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b42fafcc"},"source":["## Visualize Relationships\n","\n","### Subtask:\n","Create scatter plots or partial regression plots to visualize the relationship between each independent variable ('adults', 'children', 'babies') and the 'adr'. Provide legends for better understanding.\n"]},{"cell_type":"markdown","metadata":{"id":"8eab5fcf"},"source":["**Reasoning**:\n","To visualize the relationships as requested, I will iterate through each independent variable ('adults', 'children', 'babies') and create a scatter plot against 'adr' using `seaborn.scatterplot`, ensuring proper titles and labels for each plot.\n","\n"]},{"cell_type":"code","metadata":{"id":"9865dcbe","executionInfo":{"status":"aborted","timestamp":1771099983598,"user_tz":480,"elapsed":837,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","independent_vars = ['adults', 'children', 'babies']\n","dependent_var = 'adr'\n","\n","for col in independent_vars:\n","    plt.figure(figsize=(8, 6))\n","    sns.scatterplot(x=col, y=dependent_var, data=regression_df, alpha=0.6)\n","    plt.title(f'ADR vs. {col.replace(\"_\", \" \").title()}')\n","    plt.xlabel(col.replace(\"_\", \" \").title())\n","    plt.ylabel('Average Daily Rate (ADR)')\n","    plt.grid(True)\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d3f1dc60","executionInfo":{"status":"aborted","timestamp":1771099983602,"user_tz":480,"elapsed":830,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure(figsize=(14, 7))\n","sns.boxplot(x='market_segment', y='lead_time', hue='market_segment', data=df, palette='pastel', legend=False)\n","plt.title('Lead Time Distribution by Market Segment')\n","plt.xlabel('Market Segment')\n","plt.ylabel('Lead Time (days)')\n","plt.xticks(rotation=45, ha='right')\n","plt.grid(axis='y', linestyle='--', alpha=0.7)\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"30febbe0","executionInfo":{"status":"aborted","timestamp":1771099983606,"user_tz":480,"elapsed":820,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","cancellation_rate_by_month = df.groupby('arrival_date_month')['is_canceled'].mean().reset_index()\n","\n","# Define a consistent order for months\n","month_order = ['January', 'February', 'March', 'April', 'May', 'June',\n","               'July', 'August', 'September', 'October', 'November', 'December']\n","cancellation_rate_by_month['arrival_date_month'] = pd.Categorical(cancellation_rate_by_month['arrival_date_month'], categories=month_order, ordered=True)\n","cancellation_rate_by_month = cancellation_rate_by_month.sort_values('arrival_date_month')\n","\n","print(\"Cancellation Rate by Month:\")\n","print(cancellation_rate_by_month)\n","\n","# Map months to seasons\n","season_mapping = {\n","    'December': 'Winter', 'January': 'Winter', 'February': 'Winter',\n","    'March': 'Spring', 'April': 'Spring', 'May': 'Spring',\n","    'June': 'Summer', 'July': 'Summer', 'August': 'Summer',\n","    'September': 'Autumn', 'October': 'Autumn', 'November': 'Autumn'\n","}\n","cancellation_rate_by_month['season'] = cancellation_rate_by_month['arrival_date_month'].map(season_mapping)\n","\n","cancellation_rate_by_season = cancellation_rate_by_month.groupby('season')['is_canceled'].mean().reset_index()\n","\n","# Define a consistent order for seasons\n","season_order = ['Spring', 'Summer', 'Autumn', 'Winter']\n","cancellation_rate_by_season['season'] = pd.Categorical(cancellation_rate_by_season['season'], categories=season_order, ordered=True)\n","cancellation_rate_by_season = cancellation_rate_by_season.sort_values('season')\n","\n","print(\"\\nCancellation Rate by Season:\")\n","print(cancellation_rate_by_season)\n","\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x='season', y='is_canceled', hue='season', data=cancellation_rate_by_season, palette='coolwarm', legend=False)\n","plt.title('Cancellation Rate by Season')\n","plt.xlabel('Season')\n","plt.ylabel('Cancellation Rate')\n","plt.ylim(0, cancellation_rate_by_season['is_canceled'].max() * 1.1) # Set y-axis limit slightly above max rate\n","plt.grid(axis='y', linestyle='--', alpha=0.7)\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7f30f738","executionInfo":{"status":"aborted","timestamp":1771099983610,"user_tz":480,"elapsed":815,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["correlation = df['booking_changes'].corr(df['total_of_special_requests'])\n","print(f\"Correlation between Booking Changes and Total Special Requests: {correlation:.2f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3651d932","executionInfo":{"status":"aborted","timestamp":1771099983615,"user_tz":480,"elapsed":814,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure(figsize=(10, 6))\n","sns.scatterplot(x='booking_changes', y='total_of_special_requests', data=df, alpha=0.1)\n","plt.title('Booking Changes vs. Total Special Requests (Scatter Plot)')\n","plt.xlabel('Number of Booking Changes')\n","plt.ylabel('Total Number of Special Requests')\n","plt.grid(True)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ff1771d6","executionInfo":{"status":"aborted","timestamp":1771099983619,"user_tz":480,"elapsed":809,"user":{"displayName":"Mohd Faiz Ikbal","userId":"13615773712113797115"}}},"source":["avg_special_requests_by_changes = df.groupby('booking_changes')['total_of_special_requests'].mean().reset_index()\n","print(\"\\nAverage Special Requests by Number of Booking Changes:\")\n","print(avg_special_requests_by_changes)"],"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1766605535399}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}